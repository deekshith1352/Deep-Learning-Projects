{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da7dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8e7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=5\n",
    "img_rows,img_col=48,48\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e17e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= (r'C:\\Users\\infinity\\Desktop\\face-expression-recognition-dataset\\face-expression-recognition-dataset\\train')\n",
    "validation= (r'C:\\Users\\infinity\\Desktop\\face-expression-recognition-dataset\\face-expression-recognition-dataset\\validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator= ImageDataGenerator(rescale=1./255, rotation_range=30,shear_range=0.3, zoom_range=0.3, width_shift_range=0.4, \n",
    "                                         height_shift_range=0.4)\n",
    "validation_data_generator=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce0eafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n",
      "Found 5937 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_data_generator.flow_from_directory(train, color_mode='grayscale', target_size=(img_rows,img_col),\n",
    "                                                         batch_size= batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "\n",
    "validation_generator=validation_data_generator.flow_from_directory(validation,  color_mode='grayscale', target_size=(img_rows,img_col),\n",
    "                                 batch_size= batch_size, class_mode='categorical', shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153986b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae2a55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block 1\n",
    "model.add(Conv2D(32,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2824a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block 2\n",
    "model.add(Conv2D(64,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016d657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block 3\n",
    "model.add(Conv2D(128,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423fbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block 4\n",
    "model.add(Conv2D(256,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same', kernel_initializer='he_normal', input_shape=(img_rows,img_col,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ec1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening Block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a89d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef189bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48953c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 12, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 12, 12, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,328,037\n",
      "Trainable params: 1,325,861\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c0da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815b1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint= ModelCheckpoint('Emotion_detector_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "earlystop= EarlyStopping(monitor='val_loss', min_delta=0, patience=3, restore_best_weights=True, verbose=1 )\n",
    "reduce_lr= ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_delta=0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee91072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= [earlystop, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464fac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infinity\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdbee7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 24176\n",
    "nb_validation_samples = 3006\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c47dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-d7d1b8a23df7>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history=model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.8584 - accuracy: 0.2420\n",
      "Epoch 00001: val_loss improved from inf to 1.55498, saving model to Emotion_detector_model.h5\n",
      "755/755 [==============================] - 850s 1s/step - loss: 1.8584 - accuracy: 0.2420 - val_loss: 1.5550 - val_accuracy: 0.3125 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.5770 - accuracy: 0.2788\n",
      "Epoch 00002: val_loss improved from 1.55498 to 1.53380, saving model to Emotion_detector_model.h5\n",
      "755/755 [==============================] - 335s 443ms/step - loss: 1.5770 - accuracy: 0.2788 - val_loss: 1.5338 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.5477 - accuracy: 0.3015\n",
      "Epoch 00003: val_loss improved from 1.53380 to 1.47344, saving model to Emotion_detector_model.h5\n",
      "755/755 [==============================] - 327s 433ms/step - loss: 1.5477 - accuracy: 0.3015 - val_loss: 1.4734 - val_accuracy: 0.3592 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.5227 - accuracy: 0.3161\n",
      "Epoch 00004: val_loss did not improve from 1.47344\n",
      "755/755 [==============================] - 319s 423ms/step - loss: 1.5227 - accuracy: 0.3161 - val_loss: 1.5223 - val_accuracy: 0.3427 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "755/755 [==============================] - ETA: 0s - loss: 1.4601 - accuracy: 0.3556\n",
      "Epoch 00005: val_loss improved from 1.47344 to 1.29498, saving model to Emotion_detector_model.h5\n",
      "755/755 [==============================] - 323s 428ms/step - loss: 1.4601 - accuracy: 0.3556 - val_loss: 1.2950 - val_accuracy: 0.4556 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples//batch_size,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
